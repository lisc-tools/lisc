{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial 02: Words Analysis\n\nAnalyzing collected text data and metadata.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Words Analyses\n\nThis tutorial covers exploring & analyzing words data.\n\nFor this tutorial, we will reload and use the :class:`~.Words` object with\nthe data that we collected in the last tutorial.\n\nNote that this tutorial requires some optional dependencies, including the\n[WordCloud](https://github.com/amueller/word_cloud) module.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import the custom objects that are used to store collected words data\nfrom lisc.data import Articles, ArticlesAll\n\n# Import database and IO utilities to reload our previously collected data\nfrom lisc.io import SCDB, load_object\n\n# Import plots that are available for words data\nfrom lisc.plts.words import plot_wordcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Articles Object\n\nLISC uses custom objects to store and organize collected words data.\n\nThese objects are used internally in the :class:`~.Words` objects.\n\nIf the data collection was set to save out data as it was collected, then\n:obj:`~.Articles` objects can be loaded individually, using the label\nof the search term.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up database object\ndb = SCDB('lisc_db')\n\n# Load raw data for a particular term\nterm = 'frontal lobe'\narts = Articles(term)\narts.load(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ArticlesAll Object\n\nThe :obj:`~.ArticlesAll` object aggregates collected data across all articles collected\nfor a given search term.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Collapse data across articles\narts_all = ArticlesAll(arts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It also has methods to create and check summaries created from the aggregate data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check an example summary\narts_all.create_summary()\narts_all.print_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Words Object\n\nThe :class:`~.Words` object can also be used to reload and analyze collected data.\n\nThe `results` attribute contains a list of :class:`~.Articles` objects, one for each term.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Reload the words object, specifying to also reload the article data\nwords = load_object('tutorial_words', directory=SCDB('lisc_db'), reload_results=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the reloaded data is the raw data from the data collection.\n\nThe :meth:`~.Words.process_articles` method can be used to do some preprocessing on the\ncollected data.\n\nBy default, the :func:`~.process_articles` function is used to process articles, which\npreprocesses journal and author names, and tokenizes the text data. You can also pass in\na custom function to apply custom processing to the collected articles data.\n\nNote that some processing steps, like converting to the ArticlesAll representation,\nwill automatically apply article preprocessing.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Preprocess article data\nwords.process_articles()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also aggregate data across articles, just as we did before, directly in the Words object.\n\nIf you run the :meth:`~.Words.process_combined_results` method, then the\n`combined_results` attribute will contain the corresponding list of\n:class:`~.ArticlesAll` objects, also one for each term.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Process collected data into aggregated data objects\nwords.process_combined_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a WordCloud of the collected data for the first term\nplot_wordcloud(words.combined_results[0].words, 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Words Data\n\nThe :class:`~.Words` object also has some methods for exploring the data, including\nallowing for indexing into and looping through collected results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Index results for a specific label\nprint(words['frontal lobe'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also loop through all the articles found for a specified search term.\n\nThe iteration returns a dictionary with all the article data, which can be examined.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Iterating through articles found for a search term of interest\nfor art in words['temporal lobe']:\n    print(art['title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyzing Words Data\n\nFurther analysis depends mostly on what one wants to do with the collected data.\n\nFor example, this might include building profiles for each search term, based on\ndata in collected articles. It might also include using methods from natural language\nprocessing, such as vector embeddings and/or similarity measures.\n\nSpecific analyses might also be interested in exploring historical patterns in the literature,\nexamining, for example, the history of when certain topics were written about, and in what\njournals, by which authors.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}