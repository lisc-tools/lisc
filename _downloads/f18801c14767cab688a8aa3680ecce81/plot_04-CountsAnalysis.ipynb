{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial 04: Counts Analysis\n\nAnalyzing collected co-occurrence data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Counts Analyses\n\nThis tutorial explores analyzing collected co-occurrence data.\n\nNote that this tutorials requires some optional dependencies, including\nmatplotlib, seaborn and scipy.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import database and IO utilities to reload our previously collected data\nfrom lisc.io import SCDB, load_object\n\n# Import plots that are available for co-occurrence analysis\nfrom lisc.plts.counts import plot_matrix, plot_clustermap, plot_dendrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Reload the counts object from the last tutorial\ncounts = load_object('tutorial_counts', SCDB('lisc_db'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :class:`~.Counts` object has some helper methods to explore the collected data.\n\nFirst lets check the number of counts per term list, which we can do with the\n:meth:`~.Counts.check_data` method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Look at the collected counts data for the first set of terms\ncounts.check_data(data_type='counts', dim='A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Look at the collected counts data for the second set of terms\ncounts.check_data(data_type='counts', dim='B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization & Scores\n\nThe collected co-occurrence data includes information on the number of articles in which\nterms co-occur, as well as the number of articles for each term independently.\n\nOnce we have this data, we typically want to calculate a normalized measures,\nand/or other kinds of similarity score, to compare between terms.\n\nTo normalize the data, we can divide the co-occurrence counts by the number of articles\nper term. This allows us the examine, for example, the proportion of articles\nthat include particular co-occurrence patterns.\n\nThese measures are available using the :meth:`~.Counts.compute_score` method. This method\ncan compute different types of scores, with the type specified by  the first input to the\nmethod. Scores available include 'normalize', 'association', or 'similarity'.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute a normalization of the co-occurrence data\ncounts.compute_score('normalize', dim='A')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check out the computed normalization\nprint(counts.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The normalization is the number of articles with both terms, divided by the number of\narticles for a single term. It can therefore be interpreted as a proportion of articles\nwith term `a` that also have term `b`, or as `a & b / a`.\n\nNote that when using two different terms lists, you have to choose which list of\nterms to normalize by, which is controlled by the `dim` input.\n\nIn this case, we have calculated the normalized data as the proportion of\narticles for each anatomical term that include each perception term.\n\nAlternately, we can also calculate an association index or score, as below:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute the association index\ncounts.compute_score('association')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check out the computed score\nprint(counts.score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specifying 'association' computes the\n[Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index),\nwhich is a standard measure for measuring the similarity of samples, calculating\na normalized measure of similarity, bounded between 0 and 1.\n\nOne benefit of the Jaccard index is that you do not have to choose a terms list to normalize\nby - the calculated measure considers both lists of terms to compute an association index.\n\nThe cosine similarity of the co-occurrence data can also be calculated, with 'similarity'.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering and Plotting Co-occurrence Data\n\nThe collected co-occurrence data is a 2D matrix of counts reflecting the relationship\nbetween terms. This makes it amenable to visualizations and analyses, such as clustering,\nthat look to find structure in the data.\n\nLISC provides some functions to visualize and cluster co-occurrence data. These functions\nuse functionality offered by optional dependencies, including scipy and seaborn, which\nneed to be installed for these to run.\n\nThe functions :func:`~.plot_matrix`, :func:`~.plot_clustermap`, and :func:`~.plot_dendrogram`\noffer visualizations and clustering. You can check through each function for details on what\neach one is doing.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a matrix of the association index data\nplot_matrix(counts, attribute='score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a clustermap of the association index data\nplot_clustermap(counts, attribute='score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot a dendrogram, to cluster the terms\nplot_dendrogram(counts, attribute='score')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}